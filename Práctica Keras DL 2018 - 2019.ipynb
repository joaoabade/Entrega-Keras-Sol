{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMO 2018-2019: Práctica de Deep Learning\n",
    "\n",
    "\n",
    "### Datos de lo alumnos:\n",
    " - **Daniel Calderón**\n",
    " - **Guillermo Iglesias García**\n",
    " - **Alexandre Novo**\n",
    " - **Francisco Vilches**\n",
    "\n",
    " \n",
    "### HONESTIDAD ACADÉMICA Y POlÍTICA DE COPIAS/PLAGIO: \n",
    "La realización de los ejercicios serán realizadas en grupos de 3 ó 4 alumnos. Cada grupo deberá entregar una solución indicando arriba la lista de alumnos que componen el grupo. La discusión y el intercambio de información de carácter general con otros grupos se permite (e incluso se recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el remitir código de terceros, obtenido a través de la red o cualquier otro medio, sin referenciarlos explícitamente, se considerará plagio.\n",
    "\n",
    "Cualquier plagio o compartición de código que se detecte significará automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS los alumnos involucrados. \n",
    "\n",
    "### Datos\n",
    "Para la realización de este trabajo se deberá usar el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist). Se trata de un conjunto de datos con imágenes de articulos de la tienda Zalando. Se compone de 60.000 muestras y un test de 10.000 muestras. Cada muestra es una imagen 28x28 en escala de grises asociada con una de las 10 posibles clases. Este conjunto de datos reemplaza al clásido MNIST para problemas de machine learning. \n",
    "\n",
    "<img src='fashion-mnist-sprite.png' width=50% />\n",
    "\n",
    "MNIST es el primer conjunto de datos que los investigadores suelen usar. Se dice que \"si no funciona con MNIST, no funcionará con nada\" y \"que funcione con MNIST no implica que funcione con otros\".\n",
    "\n",
    "Algunas de las razones por las que se quiere reemplazar al clásico MNIST:\n",
    "\n",
    "   - MNIST es muy fácil. Las redes convoucionales alcanzan un 99.7% de presición. Técnicas clásicas de machine learning pueden llegar al 97% fácilmente. En realidad, la mayoría de los dígitos de MNIST se pueden diferenciar bastante bien solamente usando un pixel.\n",
    "\n",
    "<img src='one_pixel.png' width=50% />\n",
    "  \n",
    "   - MNIST está sobreusado. En abril de 2007, investigadores de Google Brain e Ian Goodfellow sugirieron a los investigadores dejar de usar MNIST.\n",
    "   - MNIST no representa a las tareas actuales de visión artificial como dijo François Chollet (creador de Keras e investigador de Google).\n",
    "   \n",
    "<img src='chollet.png' width=50% />\n",
    "\n",
    "#### Lectura de los datos\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) =  tf.keras.datasets.fashion_mnist.load_data()\n",
    "```\n",
    "\n",
    "\n",
    "## Objetivos\n",
    "Se pide crear una red neuronal para predecir la clase correspondiente de cada muestra.\n",
    "\n",
    "Se valorará:\n",
    "\n",
    "   - Las diferentes estructuras de redes probadas.\n",
    "   - El uso de diferentes técnicas de regularización.\n",
    "   - El uso de expansión de datos.\n",
    "   - Usar técnicas de fine-tuning o transfert learning.\n",
    "   \n",
    "#### Recursos\n",
    "\n",
    "Si algún grupo considera que no dispone de equipamiento suficiente para llevar a cabo este trabajo escribir un correo a dsolis@us.es. Se le proporcionará al grupo un cuenta en un servidor con GPU.\n",
    "\n",
    "## Tareas\n",
    "\n",
    "Para la realización de las tareas se podrá usar `keras`, `pandas` y `numpy`.\n",
    "\n",
    "\n",
    "## Entrega\n",
    "Se deberá entregar este archivo con las implementaciones realizadas y comentadas. Además, se pide que el alumno añada una sección final en la que comente los resultados obtenidos y los problemas encontrados a lo largo del desarrollo de la solución. \n",
    "\n",
    "Importante: No enviar el conjunto de datos, ni el modelo obtenido.\n",
    "\n",
    "**El plazo límite de entrega de la práctica es el 15 de Agosto de 2019.**\n",
    "\n",
    "\n",
    "## Dudas\n",
    "Para resolver cualquier duda contactar con David Solís (dsolis@us.es).\n",
    "\n",
    "**IMPORTANTE:** Recordad rellenar la cabecera de este fichero con vuestros nombres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "\n",
    "El primer paso de todo modelado es la preparación y carga de los datos. En este caso se trata del problema Fashion MNIST.\n",
    "\n",
    "Los datos pueden cargarse haciendo uso de Tensorflow, que proporciona una instrucción directa para descargar las imágenes ya con formato unificado de 28x28 pixels en escala de grises, para lo cual se sigue la recomendación incluida en el enunciado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 13s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) =  tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el proceso de carga de datos separa, como ya se viera en los ejemplos de clase con MNIST, adecuadamente las diversas partes de que consta este dataset: (conjunto de entrenamiento, conjunto de test), y cada uno de estos conjuntos está formado por un conjunto de datos (imágenes, en este caso concreto), con sus respectivas salidas que son las etiquetas de clasificación (y_train, y_test). \n",
    "\n",
    "Para ver que la carga de ha realizado correctamente, y que la estructura de los datos se encuentra de la manera esperada, pueden utilizarse algunas instruccionesde Python ya conocidas como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede resultar interesante ver una pequeña muestra gráfica de las imágenes que hemos cargado en nuestro dataset. Para ello se puede hacer uso de la librería matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def gen_image(arr):\n",
    "    conv = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(conv, interpolation='nearest')\n",
    "    return plt\n",
    "\n",
    "gen_image(x_test[0]).show()\n",
    "gen_image(x_test[4]).show()\n",
    "gen_image(x_test[888]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo visto hasta ahora nos puede servir como pequeña introducción y para hacernos una idea de los datos con los que vamos a trabajar. Es el momento de pasar a la siguiente fase y empezar con la construcción de modelos que nos permitan clasificar las imágenes de que disponemos.\n",
    "\n",
    "El flujo de trabajo a seguir será el habitual en casos de Machine Learning Supervisado:\n",
    "\n",
    "    1. Se le pasan al modelo (una red neuronal, en nuestro caso) los datos de entrenamiento: x_train, y_train.\n",
    "    \n",
    "    \n",
    "    2. El modelo deberá aprender a asociar las imágenes con las etiquetas correspondientes.\n",
    "    \n",
    "    3. Se comprueba la bondad del modelo sobre los datos reservados para el test (x_test), viendo si las respuestas dadas  por el modelo (predicciones) coinciden con las almacenadas en y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de diversas estructuras de redes\n",
    "\n",
    "### RN básica\n",
    "\n",
    "Como primera aproximación al problema planteado, y con vistas a obtener un punto de partida en nuestro análisis, se opta por el uso de una Red Neuronal muy básica, con una única capa de entrada y otra de salida. \n",
    "\n",
    "Se va a situar una capa de entrada con 784 (= 28 * 28) neuronas (que recibirán cada uno de los 784 pixels de cada imagen), con función de activación ReLU, y una capa de salida con 10 neuronas (una neurona para cada una de las posibles etiquetas de salida), y con activación softmax (por lo que se podrá interpretar como una probabilidad de salida que indica lo probable que es que la imagen de entrada tenga cada una de las etiquetas como salida).\n",
    "\n",
    "El primer paso es cargar la librería keras que permitirá interactuar a Python con la librería de Deep Learning que usemos (en este caso particular, Tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2987581036816600698\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como segundo paso se procede a la creación de nuestra RN básica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "\n",
    "red = models.Sequential()\n",
    "red.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "red.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de la red que hemos definido, este dispositivo consta de una secuencia de dos capas densas, que son capas neurales totalmente conectadas. La segunda (y última) capa es una capa \"softmax\" de 10 salidas, lo que significa que devolverá un vector probabilístico de 10 valores (es decir, 10 valores en  [0,1]  que suman 1). Cada uno de estos valores se interpretará la probabilidad de que la imagen actual pertenezca a una de las 10 clases (los dígitos del 0 al 9).\n",
    "\n",
    "Hasta ahora solo hemos definido la estructura de la red, pero no hemos dado ninguna información acerca de cómo se llevará a cabo el entrenamiento. Para ello, hemos de indicarle a Keras algunas características adicionales, tales como el optimizador que permitirá modificar los pesos de la red, qué función objetivo (de error) se usará para dirigir esta optimización, y la métrica que usaremos para medir cómo se va comportando la red a medida que se entrena.\n",
    "\n",
    "Keras proporciona la función compile que permite establecer estas (y otras) propiedades sobre una red ya definida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la red neuronal que vamos a usar debe recibir como dato de entrada cada imagen de forma aplanada (es decir, no como una matriz de 28x28, sino como un vector de 28x28=784 posiciones), nuestro primer paso es hacer uso de las instrucciones que proporciona Keras para transformar la forma de los datos de entrada. Además, aprovecharemos para normalizar el contenido de estas imágenes (están en escalas de grises con valores uint8 entre 0 y 255, y las pasaremos a valores float32 en  [0,1] ), algo aconsejable cuando se trabaja con este tipo de modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 28 * 28)) ## aplanar las imágenes\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "x_test = x_test.reshape((10000, 28 * 28))\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, vamos a convertir las etiquetas (que vienen en el dataset como valores enteros), en vectores binarios para que se correspondan con la salida que nuestra red puede proporcionar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparados los datos y definida la red (estructura y funcionalidad), podemos hacer uso de la instrucción fit para comenzar el proceso de entrenamiento sobre los datos que tenemos. Esencialmente, hemos de indicar sobre qué datos entrenar (entrada y salidas), cuántas iteraciones (epochs) y con qué tamaño de batch (cada cuántos ejemplos el algoritmos actualiza los pesos).\n",
    "\n",
    "Durante el proceso de entrenamiento, Keras informa de los valores que toma la función objetivo, así como de la/s métrica/s que hemos fijado en la compilación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.5559 - acc: 0.8006\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.3791 - acc: 0.8614 1s - loss:\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3356 - acc: 0.8768\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.3098 - acc: 0.8859\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.2915 - acc: 0.8924 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2346e600588>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.fit(x_train, y_train, epochs=5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos tener en cuenta que los valores mostrados son el error y métricas calculados sobre los propios datos de entrenamiento. Sin embargo, como el objetivo de un modelo de aprendizaje es generalizar bien sobre datos que el proceso de entrenamiento no ha visto anteriormente, necesitamos el conjunto de test para evaluar cómo se comporta la red sobre ejemplos que no ha usado para ajustarse.\n",
    "\n",
    "Sobre los datos de entrenamiento alcanzamos rápidamente una precisión de 0.989 (i.e. 98.9%), pero veamos cómo de bien se comporta con los datos de test (que no ha usado para aprender):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 60us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = red.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.8724\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo normal es que la red se comporte peor en los datos de test que en los datos de entrenamiento, ya que el proceso de entrenamiento consiste precisamente en ajustar los pesos para que el error cometido en estos últimos se minimice. Esta diferencia de comportamiento entre entrenamiento y test se denomina overfitting (o sobreajuste). En todo caso, con una red tan simple como la que hemos usado se alcanzan cotas de casi el 98% de aciertos.\n",
    "\n",
    "Finalmente, podemos ver las predicciones que hace la red sobre algunos datos del conjunto de test (mostramos también las etiquetas aaociadas a los datos usados, pero ten en cuenta que están en formato binarizado, y el índice 1 corresponde a la etiqueta 0, el índice 2 a la etiqueta 1, etc...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(red.predict(x_test[2:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
